# ğŸ› ï¸ MiniparLexer - Analisador LÃ©xico

Este documento descreve o **analisador lÃ©xico** do projeto **MiniparLexer**, que Ã© responsÃ¡vel por transformar o cÃ³digo-fonte em uma sequÃªncia de tokens, facilitando o processo de parsing e interpretaÃ§Ã£o.

## ğŸ“‹ VisÃ£o Geral

O analisador lÃ©xico Ã© o primeiro estÃ¡gio de um compilador ou interpretador. Ele recebe como entrada o cÃ³digo-fonte e realiza a anÃ¡lise lÃ©xica, identificando padrÃµes e convertendo-os em tokens. Esses tokens sÃ£o entÃ£o utilizados pelos mÃ³dulos de anÃ¡lise sintÃ¡tica e semÃ¢ntica.

## ğŸ“¦ Estrutura de Arquivos

O analisador lÃ©xico Ã© implementado em `lexer.py` e utiliza a enumeraÃ§Ã£o de tokens definida em `common.tokens`.

### DependÃªncias

- **common.tokens**: Define os tipos de tokens reconhecidos pelo analisador lÃ©xico.
- **re**: Biblioteca de expressÃµes regulares para a correspondÃªncia de padrÃµes lÃ©xicos.

## ğŸš€ Funcionalidades

### 1. **AnÃ¡lise LÃ©xica**

O analisador utiliza expressÃµes regulares para identificar e extrair tokens do cÃ³digo-fonte. Os principais tipos de tokens reconhecidos sÃ£o:

- **Palavras-chave**: `int`, `for`, `if`, `while`, `print`, etc.
- **Identificadores**: VariÃ¡veis e nomes de funÃ§Ãµes.
- **Literais**: NÃºmeros inteiros e strings.
- **Operadores**: `+`, `-`, `*`, `/`, `=`, `==`, etc.
- **Delimitadores**: ParÃªnteses, chaves e ponto e vÃ­rgula.

### 2. **Tratamento de Erros LÃ©xicos**

O analisador identifica caracteres desconhecidos e levanta exceÃ§Ãµes, informando a posiÃ§Ã£o e o caractere invÃ¡lido.

### 3. **GeraÃ§Ã£o de Tokens**

Os tokens sÃ£o representados como instÃ¢ncias de uma classe `Token`, contendo informaÃ§Ãµes como tipo, valor e posiÃ§Ã£o no cÃ³digo.

## ğŸ“œ Classe e MÃ©todos

### `Lexer`

A classe principal do analisador lÃ©xico.

#### **MÃ©todos:**

- `__init__(self, code: str)`: Inicializa o analisador lÃ©xico com o cÃ³digo-fonte.
- `tokenize()`: Percorre o cÃ³digo-fonte e gera a lista de tokens.
- `next_token()`: Retorna o prÃ³ximo token da sequÃªncia.
- `peek()`: Permite visualizar o prÃ³ximo token sem consumi-lo.
- `raise_error(position, char)`: Levanta um erro lÃ©xico ao encontrar um caractere invÃ¡lido.

## ğŸ“ Exemplo de Uso

```python
from lexer import Lexer

# CÃ³digo-fonte a ser analisado
code = """
int x = 10;
for (int i = 0; i < x; i = i + 1) {
    print(i);
}
"""

    